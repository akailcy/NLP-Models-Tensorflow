{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.25.3) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('train-test.json') as fopen:\n",
    "    dataset = json.load(fopen)\n",
    "    \n",
    "with open('dictionary.json') as fopen:\n",
    "    dictionary = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = dataset['train_X']\n",
    "train_Y = dataset['train_Y']\n",
    "test_X = dataset['test_X']\n",
    "test_Y = dataset['test_Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['from', 'to'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_from = dictionary['from']['dictionary']\n",
    "rev_dictionary_from = dictionary['from']['rev_dictionary']\n",
    "\n",
    "dictionary_to = dictionary['to']['dictionary']\n",
    "rev_dictionary_to = dictionary['to']['rev_dictionary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO = dictionary_from['GO']\n",
    "PAD = dictionary_from['PAD']\n",
    "EOS = dictionary_from['EOS']\n",
    "UNK = dictionary_from['UNK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rachel Pike : The science behind a climate headline EOS'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(train_X)):\n",
    "    train_X[i] += ' EOS'\n",
    "    \n",
    "train_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How can I speak in <NUM> minutes about the bonds of women over three generations , about how the astonishing strength of those bonds took hold in the life of a four - year - old girl huddled with her young sister , her mother and her grandmother for five days and nights in a small boat in the China Sea more than <NUM> years ago , bonds that took hold in the life of that small girl and never let go - - that small girl now living in San Francisco and speaking to you today ? EOS'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(test_X)):\n",
    "    test_X[i] += ' EOS'\n",
    "    \n",
    "test_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_second_dim(x, desired_size):\n",
    "    padding = tf.tile([[[0.0]]], tf.stack([tf.shape(x)[0], desired_size - tf.shape(x)[1], tf.shape(x)[2]], 0))\n",
    "    return tf.concat([x, padding], 1)\n",
    "\n",
    "class Translator:\n",
    "    def __init__(self, size_layer, num_layers, embedded_size,\n",
    "                 from_dict_size, to_dict_size, learning_rate, batch_size,\n",
    "                 force_teaching_ratio = 0.5, beam_width = 10):\n",
    "        \n",
    "        def lstm_cell(size, reuse=False):\n",
    "            return tf.nn.rnn_cell.LSTMCell(size, initializer=tf.orthogonal_initializer(),reuse=reuse)\n",
    "        \n",
    "        self.X = tf.placeholder(tf.int32, [None, None])\n",
    "        self.Y = tf.placeholder(tf.int32, [None, None])\n",
    "        self.X_seq_len = tf.count_nonzero(self.X, 1, dtype=tf.int32)\n",
    "        self.Y_seq_len = tf.count_nonzero(self.Y, 1, dtype=tf.int32)\n",
    "        batch_size = tf.shape(self.X)[0]\n",
    "        \n",
    "        encoder_embeddings = tf.Variable(tf.random_uniform([from_dict_size, embedded_size], -1, 1))\n",
    "        decoder_embeddings = tf.Variable(tf.random_uniform([to_dict_size, embedded_size], -1, 1))\n",
    "        self.encoder_out = tf.nn.embedding_lookup(encoder_embeddings, self.X)\n",
    "        \n",
    "        for n in range(num_layers):\n",
    "            (out_fw, out_bw), (state_fw, state_bw) = tf.nn.bidirectional_dynamic_rnn(\n",
    "                cell_fw = lstm_cell(size_layer // 2),\n",
    "                cell_bw = lstm_cell(size_layer // 2),\n",
    "                inputs = self.encoder_out,\n",
    "                sequence_length = self.X_seq_len,\n",
    "                dtype = tf.float32,\n",
    "                scope = 'bidirectional_rnn_%d'%(n))\n",
    "            self.encoder_out = tf.concat((out_fw, out_bw), 2)\n",
    "        bi_state_c = tf.concat((state_fw.c, state_bw.c), -1)\n",
    "        bi_state_h = tf.concat((state_fw.h, state_bw.h), -1)\n",
    "        bi_lstm_state = tf.nn.rnn_cell.LSTMStateTuple(c=bi_state_c, h=bi_state_h)\n",
    "        encoder_state = tuple([bi_lstm_state] * num_layers)\n",
    "        \n",
    "        with tf.variable_scope('decode'):\n",
    "            attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "            num_units = size_layer, \n",
    "            memory = self.encoder_out,\n",
    "            memory_sequence_length = self.X_seq_len)\n",
    "            decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell(size_layer) for _ in range(num_layers)]),\n",
    "                attention_mechanism = attention_mechanism,\n",
    "                attention_layer_size = size_layer)\n",
    "            main = tf.strided_slice(self.Y, [0, 0], [batch_size, -1], [1, 1])\n",
    "            decoder_input = tf.concat([tf.fill([batch_size, 1], GO), main], 1)\n",
    "            training_helper = tf.contrib.seq2seq.ScheduledEmbeddingTrainingHelper(\n",
    "            inputs = tf.nn.embedding_lookup(decoder_embeddings, decoder_input),\n",
    "                sequence_length = self.Y_seq_len,\n",
    "                embedding = decoder_embeddings,\n",
    "                sampling_probability = 1 - force_teaching_ratio,\n",
    "                time_major = False)\n",
    "            training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                cell = decoder_cell,\n",
    "                helper = training_helper,\n",
    "                initial_state = decoder_cell.zero_state(batch_size, tf.float32).clone(cell_state=encoder_state),\n",
    "                output_layer = tf.layers.Dense(to_dict_size))\n",
    "            training_decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                decoder = training_decoder,\n",
    "                impute_finished = True,\n",
    "                maximum_iterations = tf.reduce_max(self.Y_seq_len))\n",
    "            self.training_logits = training_decoder_output.rnn_output\n",
    "            \n",
    "        with tf.variable_scope('decode', reuse=True):\n",
    "            encoder_out_tiled = tf.contrib.seq2seq.tile_batch(self.encoder_out, beam_width)\n",
    "            encoder_state_tiled = tf.contrib.seq2seq.tile_batch(encoder_state, beam_width)\n",
    "            X_seq_len_tiled = tf.contrib.seq2seq.tile_batch(self.X_seq_len, beam_width)\n",
    "            attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "                num_units = size_layer, \n",
    "                memory = encoder_out_tiled,\n",
    "                memory_sequence_length = X_seq_len_tiled)\n",
    "            decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell(size_layer, reuse=True) for _ in range(num_layers)]),\n",
    "                attention_mechanism = attention_mechanism,\n",
    "                attention_layer_size = size_layer)\n",
    "            predicting_decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "                cell = decoder_cell,\n",
    "                embedding = decoder_embeddings,\n",
    "                start_tokens = tf.tile(tf.constant([GO], dtype=tf.int32), [batch_size]),\n",
    "                end_token = EOS,\n",
    "                initial_state = decoder_cell.zero_state(batch_size * beam_width, tf.float32).clone(cell_state = encoder_state_tiled),\n",
    "                beam_width = beam_width,\n",
    "                output_layer = tf.layers.Dense(to_dict_size, _reuse=True),\n",
    "                length_penalty_weight = 0.0)\n",
    "            predicting_decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                decoder = predicting_decoder,\n",
    "                impute_finished = False,\n",
    "                maximum_iterations = 2 * tf.reduce_max(self.X_seq_len))\n",
    "            self.predicting_ids = predicting_decoder_output.predicted_ids[:, :, 0]\n",
    "        \n",
    "        masks = tf.sequence_mask(self.Y_seq_len, tf.reduce_max(self.Y_seq_len), dtype=tf.float32)\n",
    "        self.cost = tf.contrib.seq2seq.sequence_loss(logits = self.training_logits,\n",
    "                                                     targets = self.Y,\n",
    "                                                     weights = masks)\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(self.cost)\n",
    "        y_t = tf.argmax(self.training_logits,axis=2)\n",
    "        y_t = tf.cast(y_t, tf.int32)\n",
    "        self.prediction = tf.boolean_mask(y_t, masks)\n",
    "        mask_label = tf.boolean_mask(self.Y, masks)\n",
    "        correct_pred = tf.equal(self.prediction, mask_label)\n",
    "        correct_index = tf.cast(correct_pred, tf.float32)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_layer = 512\n",
    "num_layers = 2\n",
    "embedded_size = 256\n",
    "learning_rate = 1e-3\n",
    "batch_size = 96\n",
    "epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0904 02:16:59.438081 140281505097536 deprecation.py:506] From /home/husein/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:507: calling count_nonzero (from tensorflow.python.ops.math_ops) with axis is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "reduction_indices is deprecated, use axis instead\n",
      "W0904 02:16:59.474958 140281505097536 deprecation.py:323] From <ipython-input-10-69035c3e120c>:11: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0904 02:16:59.476905 140281505097536 deprecation.py:323] From <ipython-input-10-69035c3e120c>:30: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "W0904 02:16:59.478172 140281505097536 deprecation.py:323] From /home/husein/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W0904 02:16:59.598623 140281505097536 deprecation.py:506] From /home/husein/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0904 02:17:00.259119 140281505097536 deprecation.py:323] From /home/husein/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0904 02:17:01.492953 140281505097536 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0904 02:17:01.514170 140281505097536 deprecation.py:506] From /home/husein/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0904 02:17:01.836202 140281505097536 deprecation.py:323] From <ipython-input-10-69035c3e120c>:43: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "W0904 02:17:03.070736 140281505097536 deprecation.py:323] From /home/husein/.local/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/helper.py:107: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.random.categorical` instead.\n",
      "W0904 02:17:04.141491 140281505097536 deprecation.py:323] From /home/husein/.local/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py:985: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = Translator(size_layer, num_layers, embedded_size, len(dictionary_from), \n",
    "                len(dictionary_to), learning_rate,batch_size)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_idx(corpus, dic):\n",
    "    X = []\n",
    "    for i in corpus:\n",
    "        ints = []\n",
    "        for k in i.split():\n",
    "            ints.append(dic.get(k,UNK))\n",
    "        X.append(ints)\n",
    "    return X\n",
    "\n",
    "def pad_sentence_batch(sentence_batch, pad_int):\n",
    "    padded_seqs = []\n",
    "    seq_lens = []\n",
    "    max_sentence_len = max([len(sentence) for sentence in sentence_batch])\n",
    "    for sentence in sentence_batch:\n",
    "        padded_seqs.append(sentence + [pad_int] * (max_sentence_len - len(sentence)))\n",
    "        seq_lens.append(len(sentence))\n",
    "    return padded_seqs, seq_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = str_idx(train_X, dictionary_from)\n",
    "test_X = str_idx(test_X, dictionary_from)\n",
    "train_Y = str_idx(train_Y, dictionary_to)\n",
    "test_Y = str_idx(test_Y, dictionary_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1389/1389 [20:39<00:00,  1.12it/s, accuracy=0.135, cost=5.85]\n",
      "minibatch loop: 100%|██████████| 30/30 [00:12<00:00,  2.39it/s, accuracy=0.178, cost=5.43]\n",
      "minibatch loop:   0%|          | 0/1389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, training avg loss 5.718056, training avg acc 0.134312\n",
      "epoch 1, testing avg loss 5.053389, testing avg acc 0.191853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1389/1389 [20:40<00:00,  1.12it/s, accuracy=0.198, cost=4.99]\n",
      "minibatch loop: 100%|██████████| 30/30 [00:12<00:00,  2.33it/s, accuracy=0.229, cost=4.89]\n",
      "minibatch loop:   0%|          | 0/1389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, training avg loss 4.592933, training avg acc 0.239844\n",
      "epoch 2, testing avg loss 4.481468, testing avg acc 0.247789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1389/1389 [21:13<00:00,  1.09it/s, accuracy=0.225, cost=4.55]\n",
      "minibatch loop: 100%|██████████| 30/30 [00:12<00:00,  2.34it/s, accuracy=0.257, cost=4.56]\n",
      "minibatch loop:   0%|          | 0/1389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, training avg loss 4.029598, training avg acc 0.288901\n",
      "epoch 3, testing avg loss 4.206570, testing avg acc 0.274911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1389/1389 [21:10<00:00,  1.09it/s, accuracy=0.273, cost=3.89]\n",
      "minibatch loop: 100%|██████████| 30/30 [00:12<00:00,  2.33it/s, accuracy=0.242, cost=4.49]\n",
      "minibatch loop:   0%|          | 0/1389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, training avg loss 3.675449, training avg acc 0.319440\n",
      "epoch 4, testing avg loss 4.098462, testing avg acc 0.282430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1389/1389 [21:10<00:00,  1.09it/s, accuracy=0.321, cost=3.48]\n",
      "minibatch loop: 100%|██████████| 30/30 [00:12<00:00,  2.33it/s, accuracy=0.256, cost=4.37]\n",
      "minibatch loop:   0%|          | 0/1389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, training avg loss 3.425526, training avg acc 0.342198\n",
      "epoch 5, testing avg loss 4.043292, testing avg acc 0.287465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1389/1389 [21:10<00:00,  1.09it/s, accuracy=0.335, cost=3.29]\n",
      "minibatch loop: 100%|██████████| 30/30 [00:12<00:00,  2.33it/s, accuracy=0.255, cost=4.4] \n",
      "minibatch loop:   0%|          | 0/1389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, training avg loss 3.237352, training avg acc 0.360754\n",
      "epoch 6, testing avg loss 3.998482, testing avg acc 0.292716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1389/1389 [21:11<00:00,  1.09it/s, accuracy=0.387, cost=2.99]\n",
      "minibatch loop: 100%|██████████| 30/30 [00:12<00:00,  2.33it/s, accuracy=0.26, cost=4.35] \n",
      "minibatch loop:   0%|          | 0/1389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, training avg loss 3.080521, training avg acc 0.377615\n",
      "epoch 7, testing avg loss 4.066862, testing avg acc 0.283808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1389/1389 [21:11<00:00,  1.09it/s, accuracy=0.401, cost=2.79]\n",
      "minibatch loop: 100%|██████████| 30/30 [00:12<00:00,  2.34it/s, accuracy=0.253, cost=4.34]\n",
      "minibatch loop:   0%|          | 0/1389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, training avg loss 2.950224, training avg acc 0.392324\n",
      "epoch 8, testing avg loss 4.011293, testing avg acc 0.288953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1389/1389 [21:10<00:00,  1.09it/s, accuracy=0.436, cost=2.62]\n",
      "minibatch loop: 100%|██████████| 30/30 [00:12<00:00,  2.33it/s, accuracy=0.282, cost=4.3] \n",
      "minibatch loop:   0%|          | 0/1389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, training avg loss 2.836919, training avg acc 0.405704\n",
      "epoch 9, testing avg loss 4.034942, testing avg acc 0.294021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1389/1389 [21:10<00:00,  1.09it/s, accuracy=0.481, cost=2.33]\n",
      "minibatch loop: 100%|██████████| 30/30 [00:12<00:00,  2.33it/s, accuracy=0.259, cost=4.41]\n",
      "minibatch loop:   0%|          | 0/1389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training avg loss 2.734564, training avg acc 0.418845\n",
      "epoch 10, testing avg loss 4.099306, testing avg acc 0.285718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1389/1389 [21:10<00:00,  1.09it/s, accuracy=0.506, cost=2.22]\n",
      "minibatch loop: 100%|██████████| 30/30 [00:12<00:00,  2.33it/s, accuracy=0.263, cost=4.43]\n",
      "minibatch loop:   0%|          | 0/1389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, training avg loss 2.648178, training avg acc 0.430039\n",
      "epoch 11, testing avg loss 4.077908, testing avg acc 0.289854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1389/1389 [21:10<00:00,  1.09it/s, accuracy=0.501, cost=2.18]\n",
      "minibatch loop: 100%|██████████| 30/30 [00:12<00:00,  2.32it/s, accuracy=0.24, cost=4.56] \n",
      "minibatch loop:   0%|          | 0/1389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, training avg loss 2.562009, training avg acc 0.441958\n",
      "epoch 12, testing avg loss 4.121110, testing avg acc 0.286358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1389/1389 [21:11<00:00,  1.09it/s, accuracy=0.552, cost=1.98]\n",
      "minibatch loop: 100%|██████████| 30/30 [00:12<00:00,  2.34it/s, accuracy=0.252, cost=4.55]\n",
      "minibatch loop:   0%|          | 0/1389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, training avg loss 2.478634, training avg acc 0.454529\n",
      "epoch 13, testing avg loss 4.237529, testing avg acc 0.273131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1389/1389 [21:10<00:00,  1.09it/s, accuracy=0.565, cost=1.82]\n",
      "minibatch loop: 100%|██████████| 30/30 [00:12<00:00,  2.34it/s, accuracy=0.241, cost=4.61]\n",
      "minibatch loop:   0%|          | 0/1389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, training avg loss 2.399184, training avg acc 0.466151\n",
      "epoch 14, testing avg loss 4.409642, testing avg acc 0.261398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1389/1389 [21:11<00:00,  1.09it/s, accuracy=0.598, cost=1.67]\n",
      "minibatch loop: 100%|██████████| 30/30 [00:12<00:00,  2.33it/s, accuracy=0.243, cost=4.71]\n",
      "minibatch loop:   0%|          | 0/1389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, training avg loss 2.323054, training avg acc 0.478198\n",
      "epoch 15, testing avg loss 4.541285, testing avg acc 0.250609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1389/1389 [20:43<00:00,  1.12it/s, accuracy=0.624, cost=1.64]\n",
      "minibatch loop: 100%|██████████| 30/30 [00:12<00:00,  2.41it/s, accuracy=0.248, cost=4.73]\n",
      "minibatch loop:   0%|          | 0/1389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, training avg loss 2.254886, training avg acc 0.489144\n",
      "epoch 16, testing avg loss 4.470136, testing avg acc 0.260964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1389/1389 [19:20<00:00,  1.20it/s, accuracy=0.633, cost=1.54]\n",
      "minibatch loop: 100%|██████████| 30/30 [00:12<00:00,  2.49it/s, accuracy=0.236, cost=4.96]\n",
      "minibatch loop:   0%|          | 0/1389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, training avg loss 2.195209, training avg acc 0.498573\n",
      "epoch 17, testing avg loss 4.411414, testing avg acc 0.272965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1389/1389 [19:10<00:00,  1.21it/s, accuracy=0.616, cost=1.64]\n",
      "minibatch loop: 100%|██████████| 30/30 [00:11<00:00,  2.52it/s, accuracy=0.23, cost=4.97] \n",
      "minibatch loop:   0%|          | 0/1389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, training avg loss 2.130491, training avg acc 0.509539\n",
      "epoch 18, testing avg loss 4.464022, testing avg acc 0.272088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1389/1389 [19:14<00:00,  1.20it/s, accuracy=0.63, cost=1.55] \n",
      "minibatch loop: 100%|██████████| 30/30 [00:11<00:00,  2.50it/s, accuracy=0.247, cost=4.91]\n",
      "minibatch loop:   0%|          | 0/1389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, training avg loss 2.073636, training avg acc 0.519257\n",
      "epoch 19, testing avg loss 4.623694, testing avg acc 0.259613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1389/1389 [19:48<00:00,  1.17it/s, accuracy=0.661, cost=1.45]\n",
      "minibatch loop: 100%|██████████| 30/30 [00:11<00:00,  2.52it/s, accuracy=0.253, cost=5.06]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, training avg loss 2.020019, training avg acc 0.528725\n",
      "epoch 20, testing avg loss 4.904303, testing avg acc 0.241488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "for e in range(epoch):\n",
    "    pbar = tqdm.tqdm(\n",
    "        range(0, len(train_X), batch_size), desc = 'minibatch loop')\n",
    "    train_loss, train_acc, test_loss, test_acc = [], [], [], []\n",
    "    for i in pbar:\n",
    "        index = min(i + batch_size, len(train_X))\n",
    "        maxlen = max([len(s) for s in train_X[i : index] + train_Y[i : index]])\n",
    "        batch_x, seq_x = pad_sentence_batch(train_X[i : index], PAD)\n",
    "        batch_y, seq_y = pad_sentence_batch(train_Y[i : index], PAD)\n",
    "        feed = {model.X: batch_x,\n",
    "                model.Y: batch_y}\n",
    "        accuracy, loss, _ = sess.run([model.accuracy,model.cost,model.optimizer],\n",
    "                                    feed_dict = feed)\n",
    "        train_loss.append(loss)\n",
    "        train_acc.append(accuracy)\n",
    "        pbar.set_postfix(cost = loss, accuracy = accuracy)\n",
    "    \n",
    "    \n",
    "    pbar = tqdm.tqdm(\n",
    "        range(0, len(test_X), batch_size), desc = 'minibatch loop')\n",
    "    for i in pbar:\n",
    "        index = min(i + batch_size, len(test_X))\n",
    "        batch_x, seq_x = pad_sentence_batch(test_X[i : index], PAD)\n",
    "        batch_y, seq_y = pad_sentence_batch(test_Y[i : index], PAD)\n",
    "        feed = {model.X: batch_x,\n",
    "                model.Y: batch_y,}\n",
    "        accuracy, loss = sess.run([model.accuracy,model.cost],\n",
    "                                    feed_dict = feed)\n",
    "\n",
    "        test_loss.append(loss)\n",
    "        test_acc.append(accuracy)\n",
    "        pbar.set_postfix(cost = loss, accuracy = accuracy)\n",
    "    \n",
    "    print('epoch %d, training avg loss %f, training avg acc %f'%(e+1,\n",
    "                                                                 np.mean(train_loss),np.mean(train_acc)))\n",
    "    print('epoch %d, testing avg loss %f, testing avg acc %f'%(e+1,\n",
    "                                                              np.mean(test_loss),np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_dictionary_to = {int(k): v for k, v in rev_dictionary_to.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 198)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 20\n",
    "\n",
    "batch_x, seq_x = pad_sentence_batch(test_X[: test_size], PAD)\n",
    "batch_y, seq_y = pad_sentence_batch(test_Y[: test_size], PAD)\n",
    "feed = {model.X: batch_x}\n",
    "logits = sess.run(model.predicting_ids, feed_dict = feed)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 predict: Làm thế nào tôi nói trong <NUM> phút liên quan phụ phụ nữ hơn ba thế hệ , về sức mạnh đáng kinh ngạc của những cuộc cô bé <NUM> tuổi tuổi tuổi <NUM> tuổi tuổi , mẹ và bà ấy trong suốt <NUM> đêm và bà mẹ trong vòng <NUM> ngày và đêm ở một một thuyền ở Trung Trung Quốc hơn <NUM> năm trước , kết nối mà chúng ta sống trong cuộc sống của cô ấy , hơn <NUM> năm trước , kết nối mà họ sống trong cuộc sống San Francisco và nói chuyện với bạn bạn hôm nay ? ? ngày hôm nay ? ? nói với bạn bạn ngày hôm nay ? ? nay ? ? nay ? ? nói với các bạn ngày hôm nay ? nay ? nay ? ? ? ? ' ? ? ' ? ' ? ' ? ' ? bạn muốn nói ' bạn ngày hôm nay ? ? nay ? ' ? ' ? ' ? ' ? ' ? ' ? bạn muốn nói ' bạn ngày hôm nay ? ? nay ? ' ? ? ' ? ' ? ' ? ' ?\n",
      "0 actual: Làm sao tôi có thể trình bày trong <NUM> phút về sợi dây liên kết những người phụ nữ qua ba thế hệ , về việc làm thế nào những sợi dây mạnh mẽ đáng kinh ngạc ấy đã níu chặt lấy cuộc sống của một cô bé bốn tuổi co quắp với đứa em gái nhỏ của cô bé , với mẹ và bà trong suốt năm ngày đêm trên con thuyền nhỏ lênh đênh trên Biển Đông hơn <NUM> năm trước , những sợi dây liên kết đã níu lấy cuộc đời cô bé ấy và không bao giờ rời đi - - cô bé ấy giờ sống ở San Francisco và đang nói chuyện với các bạn hôm nay ?\n",
      "\n",
      "1 predict: Đây không phải là câu chuyện hoàn chỉnh kết . . . . . . . . . . . . câu chuyện hoàn thiện . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . không . câu chuyện hoàn thành . . . . . . . . câu chuyện hoàn thành . . . . . . . . . . . . câu chuyện hoàn thành . . . . . . . . . . câu chuyện hoàn thành . . . . . . . . . . . câu chuyện hoàn thành . . . . . . . . câu chuyện hoàn thành . . . . .\n",
      "1 actual: Câu chuyện này chưa kết thúc .\n",
      "\n",
      "2 predict: Đây xếp xếp xếp xếp xếp xếp lại với nhau . . . . với nhau . . . . với nhau . ghép . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . . với nhau . ghép . với nhau . ghép . .\n",
      "2 actual: Nó là một trò chơi ghép hình vẫn đang được xếp .\n",
      "\n",
      "3 predict: Hãy để tôi giải thích một vài mảnh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . cho các bạn nghe về vài mảnh . . . . . . . . . . . . . . . . . . . . . . . . . chia sẻ các bạn về một vài mảnh . . . . . . . . . . . . . . . . . . . . . . chia sẻ các bạn về một vài mảnh . . . . . . . . . . . . . . . . . . . . . . . . . một vài mảnh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "3 actual: Hãy để tôi kể cho các bạn về vài mảnh ghép nhé .\n",
      "\n",
      "4 predict: Hình dung bức ghép đầu tiên : người đàn ông đốt hoại đời đời của mình . . . . . của anh . . . . của anh . . . . . của anh . . . . . của anh . . . . . của anh . . . . của mình . . . . . của anh . . . . của anh ta . . . . của anh . . . . của mình . . . . . của anh . . . . của mình . . . . . của anh . . . . của mình . . . . . của anh . . . . của mình . . . . . của anh . . . . của mình . . . . của mình . . . . của mình . . . . của mình . . . . . của mình . . . . . của anh . . . . của anh . . . . của mình . . . . của mình . . . . của mình . . . . của mình . .\n",
      "4 actual: Hãy tưởng tượng mảnh đầu tiên : một người đàn ông đốt cháy sự nghiệp cả đời mình .\n",
      "\n",
      "5 predict: Anh nhà , nhà thơ , một nhà viết kịch , một người đàn ông đã cân cân bằng những hi vọng về sự đoàn kết của nước quốc gia và sự tự do của nước nước . . . . . . . . . . . . do đó . do . . . . do đó . tự do của mình . . . . . . . . . . viết kịch . . . . viết kịch . tự do do tự do của mình . . . . . . . . . . viết kịch . . . . viết kịch . tự do của mình . tự do . mình . tự do . . . . . . Do đó tự do của mình . . . . . . Do đó tự do của mình . tự do . . . . . . . . Do đó tự do của mình . tự do . . . . . . . . Do đó tự do của mình . tự do . . . . . . . . . Do đó tự do của mình .\n",
      "5 actual: Ông là nhà thơ , nhà viết kịch , một người mà cả cuộc đời chênh vênh trên tia hi vọng duy nhất rằng đất nước ông sẽ độc lập tự do .\n",
      "\n",
      "6 predict: Tưởng tượng anh ta là người cộng sản trên công nghiệp , chấp nhận sự thật rằng anh ấy đã trở thành rác thải hoàn toàn . . . . . . . . . . . . toàn . rác . hoàn toàn . đống rác sạch . mình . . . . . toàn . phí rác . . . . . . . hoàn toàn . đống rác thải hoàn toàn . mình . . . . . . đống rác thải hoàn toàn . mình . . . . . . . . đống rác thải hoàn toàn . mình . . . . . . . . đống rác thải hoàn toàn . mình . . . . . . . đống rác thải hoàn toàn . mình . . . . . . . đống rác thải hoàn toàn . mình . . . . . . . đống rác thải hoàn toàn . mình . . . . . . . đống rác thải hoàn toàn . mình . . . . . . . đống rác thải hoàn toàn . mình . . . . . . . đống rác\n",
      "6 actual: Hãy tưởng tượng ông , một người cộng sản tiến vào , đối diện sự thật rằng cả cuộc đời ông đã phí hoài .\n",
      "\n",
      "7 predict: Từ lâu anh bạn đã , giờ còn lại . anh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "7 actual: Ngôn từ , qua bao năm tháng là bạn đồng hành với ông , giờ quay ra chế giễu ông .\n",
      "\n",
      "8 predict: Anh ấy lui lui trong thinh lặng . lặng . . . lặng . lặng . . lặng lặng . . im lặng . im lặng . . im lặng . im lặng . . im lặng . im lặng . . im lặng . . im lặng . im lặng . im lặng . im lặng . im lặng . lặng . im lặng . . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . . im lặng . . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng . im lặng .\n",
      "8 actual: Ông rút lui vào yên lặng .\n",
      "\n",
      "9 predict: Anh ta chết đời bởi lịch sử . . ấy bị giam hãm bởi lịch sử . . . . bị ám ảnh bởi lịch sử . . ấy bị giam hãm bởi lịch sử . . ấy . bị chia phá bởi lịch sử . . ấy . bị chia phá bởi lịch sử . . ấy . bị chia phá bởi lịch sử . . ấy . bị chia phá bởi lịch sử . . ấy . bị chia phá bởi lịch sử . . ấy . bị chia phá bởi lịch sử . . ấy . bị chia phá bởi lịch sử . . ấy . bị chia phá bởi lịch sử . . ấy . bị chia phá bởi lịch sử . . ấy . bị chia phá bởi lịch sử . . ấy . bị chia phá bởi lịch sử . . ấy . bị chia phá bởi lịch sử . . ấy . bị chia phá bởi lịch sử . . ấy . bị chia phá bởi lịch sử . . ấy . bị chia phá bởi lịch sử . . ấy . bị chia phá bởi lịch sử . . .\n",
      "9 actual: Ông qua đời , bị lịch sử quật ngã .\n",
      "\n",
      "10 predict: Ông ấy là ông tôi . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . tôi . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . tôi . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "10 actual: Ông là ông của tôi .\n",
      "\n",
      "11 predict: Tôi chưa bao giờ biết ông trong đời . . . . . . . . . . . . . . . . . đời . . . . . . . . . . đời . . . . . . . . . đời . . . . . . . . . đời . . . . . . . . . . đời . . . . . . . . . đời . . . . . . . đời . . . . . . . . . . . đời . . . . . . . . . đời . . . . . . . đời . . . . . . . . . . . đời . . . . . . . . đời . . . . . . . . đời . . . . . . . . . . đời . . . . . . . . đời . . . . . . . . đời . . . . . . . . . . đời . . . . . . . đời . . . .\n",
      "11 actual: Tôi chưa bao giờ gặp ông ngoài đời .\n",
      "\n",
      "12 predict: Nhưng cuộc sống của chúng ta còn hơn cả ký ức của chúng ta . . . . ức . . ta . . . . . . ta . ức . . ta . ức . . ta . ức . . ta . . ức . . ta . . ức . . ta . . ức . . ta . . . . . ta . . ức . mình ta . . ức . . ta . ức . . ta . . . . . ta . ức . . ta . ức . . ta . ức . . ta . . . . . ta . ức . . ta . . ức . mình . . . . . ta . . ức . mình . . . . . ta . . ức . mình ta . ức ức . mình . . . . . ta . . . . . ta . . ức . mình ta . . ức . mình . . . . . ta . . ức . mình . . . . . ta . . ức . mình . . .\n",
      "12 actual: Nhưng cuộc đời ta nhiều hơn những gì ta lưu trong kí ức nhiều .\n",
      "\n",
      "13 predict: Bà không làm giờ quên tôi quên mất cuộc đời của mình . . . . ấy . quên . ấy . quên . đời . . ấy . quên . đời . ấy . quên . đời . ấy . quên . đời . ấy . quên . ấy . sống . ấy . mất cuộc sống của ông ấy . . quên . ấy . quên . đời . ấy . mất cuộc sống của ông ấy . . quên . ấy . quên . đời . . ấy . quên . đời . ấy . quên . đời . ấy . quên . ấy . sống . ấy . mất cuộc sống của ông ấy . . quên . ấy . quên . ấy . sống . ấy . mất cuộc sống của mình . . . ấy . quên . ấy . sống . ấy . mất cuộc sống của mình . . . ấy . quên . ấy . sống . ấy . mất cuộc sống của ông ấy . . quên . ấy . sống . ấy . mất cuộc sống của mình . . . ấy . quên . ấy .\n",
      "13 actual: Bà tôi chưa bao giờ cho phép tôi quên cuộc đời của ông .\n",
      "\n",
      "14 predict: Trách nhiệm của tôi không cho phép nó trở thành vô ích , và bài học đó để hiểu rằng , vâng , lịch sử để khuấy tan chúng ta . lại . . . . . . . . . . . lại . . . . . . . . . . . . . . lại . . . . . . . . . . . . . lại . . . . . . . . lại . . . . . . . . lại . . . . . . . . . lại . . . . . . . lại . . . . lại . . . . . . . . . . . lại . . . . . . . . lại . . . . . . . lại . . . . . . . lại . . . . . . . . lại . . . . . . . lại . . . . . . . lại . . . . . . . . lại . . . . . . . lại . . . . .\n",
      "14 actual: Nhiệm vụ của tôi là không để cuộc đời ấy qua trong vô vọng , và bài học của tôi là nhận ra rằng , vâng , lịch sử đã cố quật ngã chúng tôi , nhưng chúng tôi đã chịu đựng được .\n",
      "\n",
      "15 predict: Mẫu kế hoạch của một thuyền thuyền trong lúc đầu đầu bay trượt băng biển biển biển biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển . biển\n",
      "15 actual: Mảnh ghép tiếp theo của tấm hình là một con thuyền trong sớm hoàng hôn lặng lẽ trườn ra biển .\n",
      "\n",
      "16 predict: Mẹ tôi lúc <NUM> , <NUM> khi bố ấy chết - - trong trong cuộc sắp sắp sắp , với hai bé gái nhỏ . . . . . . . . . . cô ấy . trong trong cuộc sắp sắp sắp , với hai bé gái nhỏ . . . . . trong trong cuộc sắp sắp sắp . . với hai bé gái nhỏ . . . . . trong trong cuộc sắp sắp sắp . . . với hai bé gái nhỏ . . . . . trong trong cuộc sắp sắp sắp . . . với hai bé gái nhỏ . . . . . . trong trong cuộc sắp sắp sắp . . . cô gái . . . . . trong trong cuộc sắp sắp sắp . . . cô gái nhỏ . . . . . . trong trong cuộc sắp sắp sắp . . cô gái . . . . . . trong trong cuộc sắp sắp sắp . . cô gái nhỏ . . . . . . . trong trong cuộc đời sắp sắp . . cô gái . . . . . . . . .\n",
      "16 actual: Mẹ tôi , Mai , mới <NUM> tuổi khi ba của mẹ mất - - đã lập gia đình , một cuộc hôn nhân sắp đặt trước , đã có hai cô con gái nhỏ .\n",
      "\n",
      "17 predict: Bản ấy , cuộc đời đã cam kết thành nhiệm nhiệm vụ : : trốn thoát khỏi gia đình và một cuộc sống mới ở Úc . Úc . Úc . Úc . Úc . Úc . nước Úc . . . sống mới ở Úc . Úc . Úc . Úc . Úc . nước Úc . Úc . Úc . . . sống mới ở Úc . Úc . Úc . Úc . Úc . Úc . Úc . Úc . Úc . . sống mới ở Úc . Úc . Úc . Úc . Úc . Úc . Úc . . sống mới ở Úc . Úc . Úc mới Úc . Úc . Úc . Úc . Úc . . sống mới ở Úc . Úc . Úc . Úc mới . Úc . Úc . Úc . nước Úc . . sống mới ở Úc . Úc . Úc mới . Úc . Úc . Úc mới . Úc . Úc . Úc . Úc . . sống mới ở Úc . Úc . nước Úc . nước Úc . . . sống mới ở Úc . Úc . Úc . Úc .\n",
      "17 actual: Với mẹ , cuộc đời cô đọng vào nhiệm vụ duy nhất : để gia đình mẹ trốn thoát và bắt đầu cuộc sống mới ở Úc .\n",
      "\n",
      "18 predict: Điều đó ngạc nhiên rằng cô ấy sẽ không thành công . . . . . . . thành công . . . . . công . . thành công . . thành công . . . . . thành công . . thành công . . . . . thành công . . . . . thành công . . . . thành công . . thành công . . . . . thành công . . thành công . . . . thành công . . . . . thành công . . thành công . . . . . thành công . . thành công . . . . . thành công . . thành công . . . . . thành công . . . . . thành công . . thành công . . . . . thành công . . . . . thành công . . thành công . . . . . thành công . . . . . thành công . . thành công . . . . . thành công . . thành công . . . . . thành công . . thành công . . .\n",
      "18 actual: Mẹ không bao giờ chấp nhận được là mẹ sẽ không thành công .\n",
      "\n",
      "19 predict: Vậy là sau <NUM> năm nghỉ tàu loại chống lại câu viễn dị tiểu bộ , một thuyền đưa ra mực biển mục . đánh cá đánh cá . đánh cá . đánh cá . đánh cá . đánh cá . đánh cá . đánh cá . đánh cá . đánh cá đánh cá . đánh cá . đánh cá đánh cá . đánh cá . đánh cá đánh cá . đánh cá . đánh cá đánh cá đánh cá . đánh cá . đánh cá đánh cá . đánh cá . đánh cá đánh cá đánh cá . đánh cá . đánh cá đánh cá đánh đánh cá đánh cá đánh đánh cá đánh cá đánh đánh cá đánh cá đánh đánh cá đánh cá đánh đánh cá đánh cá đánh đánh cá đánh cá đánh đánh cá đánh cá đánh đánh cá đánh cá đánh đánh cá đánh cá đánh đánh cá đánh cá đánh đánh cá đánh cá đánh đánh cá đánh đánh cá đánh cá đánh đánh cá đánh cá đánh đánh cá đánh cá đánh đánh cá đánh cá đánh đánh cá đánh cá đánh đánh cá đánh cá đánh cá đánh cá\n",
      "19 actual: Thế là sau bốn năm , một trường thiên đằng đẵng hơn cả trong truyện , một chiếc thuyền trườn ra biển nguỵ trang là thuyền đánh cá .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rejected = ['PAD', 'EOS', 'UNK', 'GO']\n",
    "\n",
    "for i in range(test_size):\n",
    "    predict = [rev_dictionary_to[i] for i in logits[i] if rev_dictionary_to[i] not in rejected]\n",
    "    actual = [rev_dictionary_to[i] for i in batch_y[i] if rev_dictionary_to[i] not in rejected]\n",
    "    print(i, 'predict:', ' '.join(predict))\n",
    "    print(i, 'actual:', ' '.join(actual))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
