{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.25.3) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('train-test.json') as fopen:\n",
    "    dataset = json.load(fopen)\n",
    "    \n",
    "with open('dictionary.json') as fopen:\n",
    "    dictionary = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = dataset['train_X']\n",
    "train_Y = dataset['train_Y']\n",
    "test_X = dataset['test_X']\n",
    "test_Y = dataset['test_Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['from', 'to'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_from = dictionary['from']['dictionary']\n",
    "rev_dictionary_from = dictionary['from']['rev_dictionary']\n",
    "\n",
    "dictionary_to = dictionary['to']['dictionary']\n",
    "rev_dictionary_to = dictionary['to']['rev_dictionary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO = dictionary_from['GO']\n",
    "PAD = dictionary_from['PAD']\n",
    "EOS = dictionary_from['EOS']\n",
    "UNK = dictionary_from['UNK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rachel Pike : The science behind a climate headline EOS'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(train_X)):\n",
    "    train_X[i] += ' EOS'\n",
    "    \n",
    "train_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How can I speak in <NUM> minutes about the bonds of women over three generations , about how the astonishing strength of those bonds took hold in the life of a four - year - old girl huddled with her young sister , her mother and her grandmother for five days and nights in a small boat in the China Sea more than <NUM> years ago , bonds that took hold in the life of that small girl and never let go - - that small girl now living in San Francisco and speaking to you today ? EOS'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(test_X)):\n",
    "    test_X[i] += ' EOS'\n",
    "    \n",
    "test_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_second_dim(x, desired_size):\n",
    "    padding = tf.tile([[[0.0]]], tf.stack([tf.shape(x)[0], desired_size - tf.shape(x)[1], tf.shape(x)[2]], 0))\n",
    "    return tf.concat([x, padding], 1)\n",
    "\n",
    "def hop_forward(memory_o, memory_i, response_proj, inputs_len, questions_len):\n",
    "    match = memory_i\n",
    "    match = pre_softmax_masking(match, inputs_len)\n",
    "    match = tf.nn.softmax(match)\n",
    "    match = post_softmax_masking(match, questions_len)\n",
    "    response = tf.multiply(match, memory_o)\n",
    "    return response_proj(response)\n",
    "\n",
    "\n",
    "def pre_softmax_masking(x, seq_len):\n",
    "    paddings = tf.fill(tf.shape(x), float('-inf'))\n",
    "    T = tf.shape(x)[1]\n",
    "    max_seq_len = tf.shape(x)[2]\n",
    "    masks = tf.sequence_mask(seq_len, max_seq_len, dtype = tf.float32)\n",
    "    masks = tf.tile(tf.expand_dims(masks, 1), [1, T, 1])\n",
    "    return tf.where(tf.equal(masks, 0), paddings, x)\n",
    "\n",
    "\n",
    "def post_softmax_masking(x, seq_len):\n",
    "    T = tf.shape(x)[2]\n",
    "    max_seq_len = tf.shape(x)[1]\n",
    "    masks = tf.sequence_mask(seq_len, max_seq_len, dtype = tf.float32)\n",
    "    masks = tf.tile(tf.expand_dims(masks, -1), [1, 1, T])\n",
    "    return x * masks\n",
    "\n",
    "def embed_seq(x, vocab_size, zero_pad = True):\n",
    "    lookup_table = tf.get_variable(\n",
    "        'lookup_table', [vocab_size, size_layer], tf.float32\n",
    "    )\n",
    "    if zero_pad:\n",
    "        lookup_table = tf.concat(\n",
    "            (tf.zeros([1, size_layer]), lookup_table[1:, :]), axis = 0\n",
    "        )\n",
    "    return tf.nn.embedding_lookup(lookup_table, x)\n",
    "\n",
    "def sinusoidal_position_encoding(inputs, mask, repr_dim):\n",
    "    T = tf.shape(inputs)[1]\n",
    "    pos = tf.reshape(tf.range(0.0, tf.to_float(T), dtype=tf.float32), [-1, 1])\n",
    "    i = np.arange(0, repr_dim, 2, np.float32)\n",
    "    denom = np.reshape(np.power(10000.0, i / repr_dim), [1, -1])\n",
    "    enc = tf.expand_dims(tf.concat([tf.sin(pos / denom), tf.cos(pos / denom)], 1), 0)\n",
    "    return tf.tile(enc, [tf.shape(inputs)[0], 1, 1]) * tf.expand_dims(tf.to_float(mask), -1)\n",
    "\n",
    "def quest_mem(x, vocab_size, size_layer):\n",
    "    en_masks = tf.sign(x)\n",
    "    x = embed_seq(x, vocab_size)\n",
    "    x += sinusoidal_position_encoding(x, en_masks, size_layer)\n",
    "    return x\n",
    "\n",
    "class Translator:\n",
    "    def __init__(self, vocab_size_from, vocab_size_to, size_layer, learning_rate, n_hops = 3):\n",
    "        \n",
    "        def lstm_cell(size, reuse=False):\n",
    "            return tf.nn.rnn_cell.LSTMCell(size, initializer=tf.orthogonal_initializer(),reuse=reuse)\n",
    "        \n",
    "        self.X = tf.placeholder(tf.int32, [None, None])\n",
    "        self.Y = tf.placeholder(tf.int32, [None, None])\n",
    "        self.X_seq_len = tf.count_nonzero(self.X, 1, dtype=tf.int32)\n",
    "        self.Y_seq_len = tf.count_nonzero(self.Y, 1, dtype=tf.int32)\n",
    "        batch_size = tf.shape(self.X)[0]\n",
    "        \n",
    "        lookup_table = tf.get_variable('lookup_table', [vocab_size_from, size_layer], tf.float32)\n",
    "        \n",
    "        with tf.variable_scope('memory_o'):\n",
    "            memory_o = quest_mem(self.X, vocab_size_from, size_layer)\n",
    "        \n",
    "        with tf.variable_scope('memory_i'):\n",
    "            memory_i = quest_mem(self.X, vocab_size_from, size_layer)\n",
    "            \n",
    "        with tf.variable_scope('interaction'):\n",
    "            response_proj = tf.layers.Dense(size_layer)\n",
    "            for _ in range(n_hops):\n",
    "                answer = hop_forward(memory_o,\n",
    "                                     memory_i,\n",
    "                                     response_proj,\n",
    "                                     self.X_seq_len,\n",
    "                                     self.X_seq_len)\n",
    "                memory_i = answer\n",
    "        \n",
    "        embedding = tf.Variable(tf.random_uniform([vocab_size_to, size_layer], -1, 1))\n",
    "        cell = tf.nn.rnn_cell.LSTMCell(size_layer)\n",
    "        vocab_proj = tf.layers.Dense(vocab_size_to)\n",
    "        state_proj = tf.layers.Dense(size_layer)\n",
    "        init_state = state_proj(tf.reduce_mean(answer, axis = 1))\n",
    "        \n",
    "        main = tf.strided_slice(self.Y, [0, 0], [batch_size, -1], [1, 1])\n",
    "        decoder_input = tf.concat([tf.fill([batch_size, 1], GO), main], 1)\n",
    "        \n",
    "        helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "            inputs = tf.nn.embedding_lookup(embedding, decoder_input),\n",
    "            sequence_length = tf.to_int32(self.Y_seq_len))\n",
    "        encoder_state = tf.nn.rnn_cell.LSTMStateTuple(c=init_state, h=init_state)\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(cell = cell,\n",
    "                                                  helper = helper,\n",
    "                                                  initial_state = encoder_state,\n",
    "                                                  output_layer = vocab_proj)\n",
    "        decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder = decoder,\n",
    "                                                                maximum_iterations = tf.reduce_max(self.Y_seq_len))\n",
    "        \n",
    "        helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(embedding = embedding,\n",
    "                                                          start_tokens = tf.tile(\n",
    "                                                              tf.constant([GO], \n",
    "                                                                          dtype=tf.int32), \n",
    "                                                              [tf.shape(init_state)[0]]),\n",
    "                                                          end_token = EOS)\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "            cell = cell,\n",
    "            helper = helper,\n",
    "            initial_state = encoder_state,\n",
    "            output_layer = vocab_proj)\n",
    "        predicting_decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "            decoder = decoder,\n",
    "            maximum_iterations = tf.reduce_max(self.X_seq_len))\n",
    "        self.training_logits = decoder_output.rnn_output\n",
    "        self.predicting_ids = predicting_decoder_output.sample_id\n",
    "        self.logits = decoder_output.sample_id\n",
    "        \n",
    "        masks = tf.sequence_mask(self.Y_seq_len, tf.reduce_max(self.Y_seq_len), dtype=tf.float32)\n",
    "        self.cost = tf.contrib.seq2seq.sequence_loss(logits = self.training_logits,\n",
    "                                                     targets = self.Y,\n",
    "                                                     weights = masks)\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(self.cost)\n",
    "        y_t = tf.argmax(self.training_logits,axis=2)\n",
    "        y_t = tf.cast(y_t, tf.int32)\n",
    "        self.prediction = tf.boolean_mask(y_t, masks)\n",
    "        mask_label = tf.boolean_mask(self.Y, masks)\n",
    "        correct_pred = tf.equal(self.prediction, mask_label)\n",
    "        correct_index = tf.cast(correct_pred, tf.float32)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_layer = 512\n",
    "learning_rate = 1e-3\n",
    "batch_size = 128\n",
    "epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:507: calling count_nonzero (from tensorflow.python.ops.math_ops) with axis is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "reduction_indices is deprecated, use axis instead\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From <ipython-input-10-f85c75c7fdf7>:42: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From <ipython-input-10-f85c75c7fdf7>:20: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From <ipython-input-10-f85c75c7fdf7>:85: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-10-f85c75c7fdf7>:95: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = Translator(len(dictionary_from), len(dictionary_to), size_layer, learning_rate)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_idx(corpus, dic):\n",
    "    X = []\n",
    "    for i in corpus:\n",
    "        ints = []\n",
    "        for k in i.split():\n",
    "            ints.append(dic.get(k,UNK))\n",
    "        X.append(ints)\n",
    "    return X\n",
    "\n",
    "def pad_sentence_batch(sentence_batch, pad_int):\n",
    "    padded_seqs = []\n",
    "    seq_lens = []\n",
    "    max_sentence_len = max([len(sentence) for sentence in sentence_batch])\n",
    "    for sentence in sentence_batch:\n",
    "        padded_seqs.append(sentence + [pad_int] * (max_sentence_len - len(sentence)))\n",
    "        seq_lens.append(len(sentence))\n",
    "    return padded_seqs, seq_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = str_idx(train_X, dictionary_from)\n",
    "test_X = str_idx(test_X, dictionary_from)\n",
    "train_Y = str_idx(train_Y, dictionary_to)\n",
    "test_Y = str_idx(test_Y, dictionary_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1042/1042 [05:03<00:00,  3.44it/s, accuracy=0.188, cost=5.13]\n",
      "minibatch loop: 100%|██████████| 23/23 [00:03<00:00,  7.33it/s, accuracy=0.203, cost=4.81]\n",
      "minibatch loop:   0%|          | 0/1042 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, training avg loss 5.301888, training avg acc 0.158684\n",
      "epoch 1, testing avg loss 4.682847, testing avg acc 0.213214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1042/1042 [05:02<00:00,  3.45it/s, accuracy=0.212, cost=4.62]\n",
      "minibatch loop: 100%|██████████| 23/23 [00:02<00:00,  7.76it/s, accuracy=0.254, cost=4.52]\n",
      "minibatch loop:   0%|          | 0/1042 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, training avg loss 4.417816, training avg acc 0.240071\n",
      "epoch 2, testing avg loss 4.401243, testing avg acc 0.243452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1042/1042 [05:01<00:00,  3.45it/s, accuracy=0.239, cost=4.27]\n",
      "minibatch loop: 100%|██████████| 23/23 [00:02<00:00,  7.77it/s, accuracy=0.271, cost=4.39]\n",
      "minibatch loop:   0%|          | 0/1042 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, training avg loss 4.165625, training avg acc 0.262169\n",
      "epoch 3, testing avg loss 4.274698, testing avg acc 0.258111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1042/1042 [05:01<00:00,  3.45it/s, accuracy=0.257, cost=4]   \n",
      "minibatch loop: 100%|██████████| 23/23 [00:02<00:00,  7.82it/s, accuracy=0.249, cost=4.33]\n",
      "minibatch loop:   0%|          | 0/1042 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, training avg loss 4.002380, training avg acc 0.276652\n",
      "epoch 4, testing avg loss 4.206110, testing avg acc 0.268251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1042/1042 [05:01<00:00,  3.45it/s, accuracy=0.283, cost=3.77]\n",
      "minibatch loop: 100%|██████████| 23/23 [00:02<00:00,  7.73it/s, accuracy=0.254, cost=4.28]\n",
      "minibatch loop:   0%|          | 0/1042 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, training avg loss 3.880872, training avg acc 0.288267\n",
      "epoch 5, testing avg loss 4.168355, testing avg acc 0.273869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1042/1042 [05:01<00:00,  3.46it/s, accuracy=0.31, cost=3.55] \n",
      "minibatch loop: 100%|██████████| 23/23 [00:02<00:00,  7.77it/s, accuracy=0.266, cost=4.26]\n",
      "minibatch loop:   0%|          | 0/1042 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, training avg loss 3.783415, training avg acc 0.298490\n",
      "epoch 6, testing avg loss 4.150167, testing avg acc 0.276515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1042/1042 [05:01<00:00,  3.46it/s, accuracy=0.34, cost=3.35] \n",
      "minibatch loop: 100%|██████████| 23/23 [00:02<00:00,  7.74it/s, accuracy=0.277, cost=4.23]\n",
      "minibatch loop:   0%|          | 0/1042 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, training avg loss 3.701626, training avg acc 0.307492\n",
      "epoch 7, testing avg loss 4.141633, testing avg acc 0.278990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1042/1042 [05:14<00:00,  3.31it/s, accuracy=0.362, cost=3.18]\n",
      "minibatch loop: 100%|██████████| 23/23 [00:02<00:00,  7.88it/s, accuracy=0.266, cost=4.22]\n",
      "minibatch loop:   0%|          | 0/1042 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, training avg loss 3.630026, training avg acc 0.315532\n",
      "epoch 8, testing avg loss 4.141056, testing avg acc 0.280207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1042/1042 [05:14<00:00,  3.31it/s, accuracy=0.388, cost=3.01]\n",
      "minibatch loop: 100%|██████████| 23/23 [00:02<00:00,  7.89it/s, accuracy=0.277, cost=4.22]\n",
      "minibatch loop:   0%|          | 0/1042 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, training avg loss 3.564586, training avg acc 0.323480\n",
      "epoch 9, testing avg loss 4.141120, testing avg acc 0.283021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1042/1042 [05:13<00:00,  3.32it/s, accuracy=0.404, cost=2.85]\n",
      "minibatch loop: 100%|██████████| 23/23 [00:02<00:00,  7.83it/s, accuracy=0.266, cost=4.23]\n",
      "minibatch loop:   0%|          | 0/1042 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training avg loss 3.504956, training avg acc 0.331178\n",
      "epoch 10, testing avg loss 4.151076, testing avg acc 0.283575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1042/1042 [05:12<00:00,  3.33it/s, accuracy=0.429, cost=2.72]\n",
      "minibatch loop: 100%|██████████| 23/23 [00:04<00:00,  5.17it/s, accuracy=0.254, cost=4.26]\n",
      "minibatch loop:   0%|          | 0/1042 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, training avg loss 3.451179, training avg acc 0.338148\n",
      "epoch 11, testing avg loss 4.162719, testing avg acc 0.284683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1042/1042 [05:14<00:00,  3.31it/s, accuracy=0.446, cost=2.6] \n",
      "minibatch loop: 100%|██████████| 23/23 [00:02<00:00,  7.77it/s, accuracy=0.26, cost=4.29] \n",
      "minibatch loop:   0%|          | 0/1042 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, training avg loss 3.402817, training avg acc 0.344295\n",
      "epoch 12, testing avg loss 4.184766, testing avg acc 0.284841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1042/1042 [05:15<00:00,  3.31it/s, accuracy=0.468, cost=2.51]\n",
      "minibatch loop: 100%|██████████| 23/23 [00:02<00:00,  7.87it/s, accuracy=0.277, cost=4.32]\n",
      "minibatch loop:   0%|          | 0/1042 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, training avg loss 3.360376, training avg acc 0.349804\n",
      "epoch 13, testing avg loss 4.189361, testing avg acc 0.286279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1042/1042 [05:02<00:00,  3.45it/s, accuracy=0.479, cost=2.42]\n",
      "minibatch loop: 100%|██████████| 23/23 [00:02<00:00,  7.87it/s, accuracy=0.254, cost=4.35]\n",
      "minibatch loop:   0%|          | 0/1042 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, training avg loss 3.319956, training avg acc 0.355186\n",
      "epoch 14, testing avg loss 4.193111, testing avg acc 0.286875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1042/1042 [05:01<00:00,  3.46it/s, accuracy=0.497, cost=2.3] \n",
      "minibatch loop: 100%|██████████| 23/23 [00:02<00:00,  7.77it/s, accuracy=0.26, cost=4.38] \n",
      "minibatch loop:   0%|          | 0/1042 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, training avg loss 3.278140, training avg acc 0.361229\n",
      "epoch 15, testing avg loss 4.211889, testing avg acc 0.286269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1042/1042 [05:01<00:00,  3.45it/s, accuracy=0.525, cost=2.19]\n",
      "minibatch loop: 100%|██████████| 23/23 [00:02<00:00,  7.90it/s, accuracy=0.243, cost=4.41]\n",
      "minibatch loop:   0%|          | 0/1042 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, training avg loss 3.237600, training avg acc 0.367159\n",
      "epoch 16, testing avg loss 4.235345, testing avg acc 0.285605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1042/1042 [05:01<00:00,  3.46it/s, accuracy=0.556, cost=2.09]\n",
      "minibatch loop: 100%|██████████| 23/23 [00:02<00:00,  7.75it/s, accuracy=0.243, cost=4.46]\n",
      "minibatch loop:   0%|          | 0/1042 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, training avg loss 3.199348, training avg acc 0.372777\n",
      "epoch 17, testing avg loss 4.262734, testing avg acc 0.284528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1042/1042 [05:00<00:00,  3.47it/s, accuracy=0.573, cost=2.01]\n",
      "minibatch loop: 100%|██████████| 23/23 [00:02<00:00,  7.84it/s, accuracy=0.243, cost=4.5] \n",
      "minibatch loop:   0%|          | 0/1042 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, training avg loss 3.163599, training avg acc 0.378143\n",
      "epoch 18, testing avg loss 4.293229, testing avg acc 0.282703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1042/1042 [05:01<00:00,  3.45it/s, accuracy=0.594, cost=1.94]\n",
      "minibatch loop: 100%|██████████| 23/23 [00:02<00:00,  7.81it/s, accuracy=0.249, cost=4.55]\n",
      "minibatch loop:   0%|          | 0/1042 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, training avg loss 3.131367, training avg acc 0.382865\n",
      "epoch 19, testing avg loss 4.338955, testing avg acc 0.279106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 1042/1042 [05:15<00:00,  3.30it/s, accuracy=0.608, cost=1.89]\n",
      "minibatch loop: 100%|██████████| 23/23 [00:02<00:00,  7.69it/s, accuracy=0.237, cost=4.58]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, training avg loss 3.106003, training avg acc 0.386378\n",
      "epoch 20, testing avg loss 4.348935, testing avg acc 0.280245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "for e in range(epoch):\n",
    "    pbar = tqdm.tqdm(\n",
    "        range(0, len(train_X), batch_size), desc = 'minibatch loop')\n",
    "    train_loss, train_acc, test_loss, test_acc = [], [], [], []\n",
    "    for i in pbar:\n",
    "        index = min(i + batch_size, len(train_X))\n",
    "        maxlen = max([len(s) for s in train_X[i : index] + train_Y[i : index]])\n",
    "        batch_x, seq_x = pad_sentence_batch(train_X[i : index], PAD)\n",
    "        batch_y, seq_y = pad_sentence_batch(train_Y[i : index], PAD)\n",
    "        feed = {model.X: batch_x,\n",
    "                model.Y: batch_y}\n",
    "        accuracy, loss, _ = sess.run([model.accuracy,model.cost,model.optimizer],\n",
    "                                    feed_dict = feed)\n",
    "        train_loss.append(loss)\n",
    "        train_acc.append(accuracy)\n",
    "        pbar.set_postfix(cost = loss, accuracy = accuracy)\n",
    "    \n",
    "    \n",
    "    pbar = tqdm.tqdm(\n",
    "        range(0, len(test_X), batch_size), desc = 'minibatch loop')\n",
    "    for i in pbar:\n",
    "        index = min(i + batch_size, len(test_X))\n",
    "        batch_x, seq_x = pad_sentence_batch(test_X[i : index], PAD)\n",
    "        batch_y, seq_y = pad_sentence_batch(test_Y[i : index], PAD)\n",
    "        feed = {model.X: batch_x,\n",
    "                model.Y: batch_y,}\n",
    "        accuracy, loss = sess.run([model.accuracy,model.cost],\n",
    "                                    feed_dict = feed)\n",
    "\n",
    "        test_loss.append(loss)\n",
    "        test_acc.append(accuracy)\n",
    "        pbar.set_postfix(cost = loss, accuracy = accuracy)\n",
    "    \n",
    "    print('epoch %d, training avg loss %f, training avg acc %f'%(e+1,\n",
    "                                                                 np.mean(train_loss),np.mean(train_acc)))\n",
    "    print('epoch %d, testing avg loss %f, testing avg acc %f'%(e+1,\n",
    "                                                              np.mean(test_loss),np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_dictionary_to = {int(k): v for k, v in rev_dictionary_to.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 99)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 20\n",
    "\n",
    "batch_x, seq_x = pad_sentence_batch(test_X[: test_size], PAD)\n",
    "batch_y, seq_y = pad_sentence_batch(test_Y[: test_size], PAD)\n",
    "feed = {model.X: batch_x}\n",
    "logits = sess.run(model.predicting_ids, feed_dict = feed)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 predict: Tôi đã gặp một người đàn ông tên là Kyle Lovett phát hiện ra rằng \" Tôi không biết , nhưng tôi không biết liệu tôi có thể làm gì với tôi , nhưng tôi nghĩ , tôi sẽ không bao giờ quên , và tôi nghĩ , tôi không biết , nhưng AJ Jacobs có thể là một người đàn ông , và tôi không thể nói được , nhưng tôi không biết liệu tôi có thể làm gì với tôi , nhưng tôi nghĩ rằng , nếu tôi có thể nói với bạn rằng , chúng ta\n",
      "0 actual: Làm sao tôi có thể trình bày trong <NUM> phút về sợi dây liên kết những người phụ nữ qua ba thế hệ , về việc làm thế nào những sợi dây mạnh mẽ đáng kinh ngạc ấy đã níu chặt lấy cuộc sống của một cô bé bốn tuổi co quắp với đứa em gái nhỏ của cô bé , với mẹ và bà trong suốt năm ngày đêm trên con thuyền nhỏ lênh đênh trên Biển Đông hơn <NUM> năm trước , những sợi dây liên kết đã níu lấy cuộc đời cô bé ấy và không bao giờ rời đi - - cô bé ấy giờ sống ở San Francisco và đang nói chuyện với các bạn hôm nay ?\n",
      "\n",
      "1 predict: Đây là một ví dụ khác . Đây là một trong những điều tuyệt vời . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết\n",
      "1 actual: Câu chuyện này chưa kết thúc .\n",
      "\n",
      "2 predict: Đây là một trong những điều mà chúng tôi đã làm . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết\n",
      "2 actual: Nó là một trò chơi ghép hình vẫn đang được xếp .\n",
      "\n",
      "3 predict: Hãy để tôi cho các bạn thấy một ví dụ khác . Chúng tôi đã làm điều đó . Tôi sẽ nói về việc này . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "3 actual: Hãy để tôi kể cho các bạn về vài mảnh ghép nhé .\n",
      "\n",
      "4 predict: Một người phụ nữ , tôi đã nói với tôi rằng Meg Ryan có thể làm được . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "4 actual: Hãy tưởng tượng mảnh đầu tiên : một người đàn ông đốt cháy sự nghiệp cả đời mình .\n",
      "\n",
      "5 predict: Đây là một ví dụ khác : \" Tôi biết tôi đang ở đâu , tôi sẽ không bao giờ quên , \" Tôi sẽ không bao giờ quên được với tôi . \" Và tôi nói , \" Tôi không biết . \" Tôi sẽ nói về nó . \" Điều này là một phần của câu chuyện . \" Tôi sẽ nói về điều này . \" Tôi sẽ nói về nó . \" Điều này là một câu chuyện . \" Tôi sẽ nói về điều này . \" Tôi sẽ nói về nó . \"\n",
      "5 actual: Ông là nhà thơ , nhà viết kịch , một người mà cả cuộc đời chênh vênh trên tia hi vọng duy nhất rằng đất nước ông sẽ độc lập tự do .\n",
      "\n",
      "6 predict: Những người đàn ông này , họ là người duy nhất trong nhóm của họ , và họ đã làm việc với họ . \" Tôi đã làm vậy . \" \" . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "6 actual: Hãy tưởng tượng ông , một người cộng sản tiến vào , đối diện sự thật rằng cả cuộc đời ông đã phí hoài .\n",
      "\n",
      "7 predict: Một trong những người phụ nữ là người Mỹ . Tôi đã không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết .\n",
      "7 actual: Ngôn từ , qua bao năm tháng là bạn đồng hành với ông , giờ quay ra chế giễu ông .\n",
      "\n",
      "8 predict: Đây là một ví dụ khác . Đây là một trong những điều tôi muốn nói . \" Phải . \" Cảm ơn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "8 actual: Ông rút lui vào yên lặng .\n",
      "\n",
      "9 predict: Tôi đã nói với các bạn rằng , \" Tôi không biết . \" Tôi sẽ nói về nó . \" Điều này là một câu chuyện . \" Tôi sẽ nói về nó . \" Điều này là một câu chuyện . \" Tôi sẽ nói về điều này . \" Điều gì sẽ xảy ra ? \" . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "9 actual: Ông qua đời , bị lịch sử quật ngã .\n",
      "\n",
      "10 predict: Đó là một câu chuyện tuyệt vời . Tôi không biết . Tôi là một người đàn ông . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết .\n",
      "10 actual: Ông là ông của tôi .\n",
      "\n",
      "11 predict: Tôi đã không biết được gì về nó . \" Tôi sẽ nói về điều đó . \" . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "11 actual: Tôi chưa bao giờ gặp ông ngoài đời .\n",
      "\n",
      "12 predict: Nhưng chúng ta có thể thấy những điều này rất quan trọng . Và đây là một ví dụ . Có thể là một trong những điều chúng tôi làm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "12 actual: Nhưng cuộc đời ta nhiều hơn những gì ta lưu trong kí ức nhiều .\n",
      "\n",
      "13 predict: Tôi đã nói chuyện với tôi . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết .\n",
      "13 actual: Bà tôi chưa bao giờ cho phép tôi quên cuộc đời của ông .\n",
      "\n",
      "14 predict: Một trong những điều tôi muốn nói hôm nay là một trong những điều mà tôi muốn nói với các bạn , và tôi nghĩ rằng đó là một vấn đề lớn , nhưng nó thực sự là một vấn đề lớn . Nó là một vấn đề lớn . Nó là một vấn đề . Nó là một vấn đề . Nó là một vấn đề . Nó là một vấn đề . Nó là một vấn đề . Nó là một vấn đề . Nó là một vấn đề lớn . Nó là một vấn đề lớn\n",
      "14 actual: Nhiệm vụ của tôi là không để cuộc đời ấy qua trong vô vọng , và bài học của tôi là nhận ra rằng , vâng , lịch sử đã cố quật ngã chúng tôi , nhưng chúng tôi đã chịu đựng được .\n",
      "\n",
      "15 predict: Một trong những điều tôi muốn nói là khi tôi có thể làm được điều đó . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "15 actual: Mảnh ghép tiếp theo của tấm hình là một con thuyền trong sớm hoàng hôn lặng lẽ trườn ra biển .\n",
      "\n",
      "16 predict: Vào năm <NUM> , tôi đã học được nhiều điều về việc tôi đã làm được điều đó , và tôi đã nói với các bạn . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết . Tôi không biết .\n",
      "16 actual: Mẹ tôi , Mai , mới <NUM> tuổi khi ba của mẹ mất - - đã lập gia đình , một cuộc hôn nhân sắp đặt trước , đã có hai cô con gái nhỏ .\n",
      "\n",
      "17 predict: Một trong những điều tôi đã làm là tôi đã làm việc với các nhà khoa học và kỹ sư , các nhà khoa học , khoa học . Cảm ơn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "17 actual: Với mẹ , cuộc đời cô đọng vào nhiệm vụ duy nhất : để gia đình mẹ trốn thoát và bắt đầu cuộc sống mới ở Úc .\n",
      "\n",
      "18 predict: Đây là một ví dụ khác về sự phức hợp của sự cân bằng . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "18 actual: Mẹ không bao giờ chấp nhận được là mẹ sẽ không thành công .\n",
      "\n",
      "19 predict: Tôi đã nói với các bạn rằng , \" Tôi muốn nói với các bạn rằng bạn đang làm gì ? \" Tôi nghĩ là một trong những điều tuyệt vời nhất , bởi vì nó thực sự là một vấn đề lớn . Nó là một vấn đề lớn . Nó là một vấn đề lớn . Nó là một vấn đề . Nó là một vấn đề . Nó là một vấn đề . Nó là một vấn đề . Nó là một vấn đề . Nó là một vấn đề . Nó là một vấn đề\n",
      "19 actual: Thế là sau bốn năm , một trường thiên đằng đẵng hơn cả trong truyện , một chiếc thuyền trườn ra biển nguỵ trang là thuyền đánh cá .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rejected = ['PAD', 'EOS', 'UNK', 'GO']\n",
    "\n",
    "for i in range(test_size):\n",
    "    predict = [rev_dictionary_to[i] for i in logits[i] if rev_dictionary_to[i] not in rejected]\n",
    "    actual = [rev_dictionary_to[i] for i in batch_y[i] if rev_dictionary_to[i] not in rejected]\n",
    "    print(i, 'predict:', ' '.join(predict))\n",
    "    print(i, 'actual:', ' '.join(actual))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
